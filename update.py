import requests
from bs4 import BeautifulSoup
import yfinance as yf
import datetime
import re

# === å…¨çƒä¸»è¦è‚¡å¸‚å³æ™‚åƒ¹æ ¼ ===
markets = {
    "é“ç“ŠæŒ‡æ•¸ (DJI)": "^DJI",
    "NASDAQ": "^IXIC",
    "S&P 500": "^GSPC",
    "æ—¥ç¶“ 225": "^N225",
    "å°ç£åŠ æ¬Š": "^TWII",
    "ä¸Šè­‰æŒ‡æ•¸": "000001.SS",
    "å¾·åœ‹ DAX": "^GDAXI"
}

def fetch_markets():
    rows = ""
    for name, symbol in markets.items():
        ticker = yf.Ticker(symbol)
        try:
            price = ticker.fast_info["lastPrice"]
            price = round(price, 2)
            rows += f"<li>{name}: {price}</li>"
        except:
            rows += f"<li>{name}: è®€å–å¤±æ•—</li>"
    return rows

# === è‹±æ–‡æ–°è RSS ===
RSS_LIST_EN = [
    ("BBC World", "http://feeds.bbci.co.uk/news/world/rss.xml"),
    ("CNN Top Stories", "http://rss.cnn.com/rss/edition.rss"),
    # Reuters å®˜æ–¹ HTTPS RSSï¼Œå¦‚æœè§£æå¤±æ•—æœƒè·³é
    ("Reuters World", "https://www.reuters.com/rssFeed/worldNews")
]

def fetch_rss_news(rss_list):
    html = ""
    for name, url in rss_list:
        try:
            r = requests.get(url, timeout=10)
            r.encoding = r.apparent_encoding
            root = ET.fromstring(r.text)
            items = root.findall(".//item")[:20]
            for item in items:
                title = item.find("title").text if item.find("title") is not None else "ç„¡æ¨™é¡Œ"
                link = item.find("link").text if item.find("link") is not None else "#"
                html += f'<li><a href="{link}" target="_blank">{title}</a> <small>({name})</small></li>\n'
        except Exception as e:
            html += f"<li>{name} è®€å–å¤±æ•—: {e}</li>\n"
    return html

# === ä¸­æ–‡æ–°è RSS (ä¸­å¤®ç¤¾åœ‹éš›) ===
def fetch_cn_news():
    name = "ä¸­å¤®ç¤¾åœ‹éš›"
    url = "https://feeds.feedburner.com/rsscna/intworld"
    html = ""
    try:
        r = requests.get(url, timeout=10)
        r.encoding = r.apparent_encoding
        root = ET.fromstring(r.text)
        items = root.findall(".//item")[:20]
        for item in items:
            title = item.find("title").text if item.find("title") is not None else "ç„¡æ¨™é¡Œ"
            link = item.find("link").text if item.find("link") is not None else "#"
            html += f'<li><a href="{link}" target="_blank">{title}</a> <small>({name})</small></li>\n'
    except Exception as e:
        html += f"<li>{name} è®€å–å¤±æ•—: {e}</li>\n"
    return html

# === æ”¿ç¶“æ‘˜è¦ ===
def fetch_geo():
    try:
        r = requests.get("https://www.reuters.com/world/", timeout=10)
        r.encoding = r.apparent_encoding
        soup_text = r.text
        links = re.findall(r'href="(/world/[^"]+)"', soup_text)[:8]
        geo_html = ""
        for link in links:
            url = "https://www.reuters.com" + link
            title = link.split("/")[-1].replace("-", " ").title()
            geo_html += f'<li><a href="{url}" target="_blank">{title}</a></li>\n'
        return geo_html
    except:
        return "<li>Reuters è®€å–å¤±æ•—</li>"

# === æ›´æ–°é¦–é  ===
def update_html():
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
    html_path = "index.html"
    with open(html_path, "r", encoding="utf-8") as f:
        html = f.read()

    import re
    html = re.sub(r"<h2>ğŸ“ˆ å…¨çƒè‚¡å¸‚æŒ‡æ•¸.*</body>", "</body>", html, flags=re.S)

    new_block = f"""
<h2>ğŸ“ˆ å…¨çƒè‚¡å¸‚æŒ‡æ•¸ï¼ˆæ›´æ–°æ™‚é–“ï¼š{now}ï¼‰</h2>
<ul>{fetch_markets()}</ul>

<h2>ğŸ“° åœ‹éš›é‡å¤§æ–°èï¼ˆè‹±æ–‡ï¼‰</h2>
<ul>{fetch_rss_news(RSS_LIST_EN)}</ul>

<h2>ğŸ“° åœ‹éš›é‡å¤§æ–°èï¼ˆä¸­æ–‡ï¼‰</h2>
<ul>{fetch_cn_news()}</ul>

<h2>ğŸŒ æ”¿ç¶“å±€å‹¢æ‘˜è¦</h2>
<ul>{fetch_geo()}</ul>
</body>
"""
    html = html.replace("</body>", new_block)

    with open(html_path, "w", encoding="utf-8") as f:
        f.write(html)

    print("é¦–é æ›´æ–°å®Œæˆ âœ…")

if __name__ == "__main__":
    update_html()

