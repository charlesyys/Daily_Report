import requests
from bs4 import BeautifulSoup
import yfinance as yf
import datetime
import re
import xml.etree.ElementTree as ET
import pytz # ğŸš¨ æ–°å¢ï¼šç”¨æ–¼æ™‚å€è™•ç†

# === å…¨çƒä¸»è¦è‚¡å¸‚å³æ™‚åƒ¹æ ¼ ===
markets = {
    "é“ç“ŠæŒ‡æ•¸ (DJI)": "^DJI",
    "NASDAQ": "^IXIC",
    "S&P 500": "^GSPC",
    "æ—¥ç¶“ 225": "^N225",
    "å°ç£åŠ æ¬Š": "^TWII",
    "ä¸Šè­‰æŒ‡æ•¸": "000001.SS",
    "å¾·åœ‹ DAX": "^GDAXI"
}

def fetch_markets():
    """ç²å–è‚¡å¸‚æ•¸æ“šä¸¦æ ¼å¼åŒ–ç‚º HTML åˆ—è¡¨"""
    rows = ""
    for name, symbol in markets.items():
        ticker = yf.Ticker(symbol)
        try:
            # yfinance çš„ fast_info æä¾›äº†å¿«é€Ÿç²å–æœ€æ–°åƒ¹æ ¼çš„æ–¹å¼
            price = ticker.fast_info["lastPrice"]
            price = round(price, 2)
            rows += f"<li>{name}: {price}</li>"
        except:
            rows += f"<li>{name}: è®€å–å¤±æ•—</li>"
    return rows

# === è‹±æ–‡æ–°è RSS ===
RSS_LIST_EN = [
    ("BBC World", "http://feeds.bbci.co.uk/news/world/rss.xml"),
    ("CNN Top Stories", "http://rss.cnn.com/rss/edition.rss"),
    # Reuters å®˜æ–¹ HTTPS RSSï¼Œå¦‚æœè§£æå¤±æ•—æœƒè·³é
    ("Reuters World", "https://www.reuters.com/rssFeed/worldNews")
]

def fetch_rss_news(rss_list):
    """å¾ RSS é€£çµç²å–æ–°èä¸¦æ ¼å¼åŒ–ç‚º HTML åˆ—è¡¨"""
    html = ""
    for name, url in rss_list:
        try:
            r = requests.get(url, timeout=10)
            r.encoding = r.apparent_encoding
            # ä½¿ç”¨ ET.fromstring è™•ç† XML
            root = ET.fromstring(r.text)
            items = root.findall(".//item")[:20]
            # å°‹æ‰¾å‰ 20 æ¢æ–°è
            for item in items:
                title = item.find("title").text if item.find("title") is not None else "ç„¡æ¨™é¡Œ"
                link = item.find("link").text if item.find("link") is not None else "#"
                html += f'<li><a href="{link}" target="_blank">{title}</a> <small>({name})</small></li>\n'
        except Exception as e:
            # éŒ¯èª¤è™•ç†
            html += f"<li>{name} è®€å–å¤±æ•—: {e}</li>\n"
    return html

# === ä¸­æ–‡æ–°è RSS (ä¸­å¤®ç¤¾åœ‹éš›) ===
RSS_LIST_CN = [
    # åœ‹éš›èˆ‡ç¶œåˆ (ä¸­å¤®ç¤¾ - ä¿æŒ)
    ("ä¸­å¤®ç¤¾ åœ‹éš›", "https://feeds.feedburner.com/rsscna/intworld"),
    # åœ‹éš›èˆ‡ç¶œåˆ (æ±æ£®æ–°è)
    ("æ±æ£®æ–°è ç„¦é»", "https://news.ebc.net.tw/Rss/news"),
    # Google
    ("Google News å°ç£ç„¦é»", "https://news.google.com/rss?hl=zh-TW&gl=TW&ceid=TW:zh-Hant"),
    # è²¡ç¶“å°ˆæ¥­ (ETtoday è²¡ç¶“)
    ("ETtoday è²¡ç¶“", "https://feeds.feedburner.com/ettoday/finance"),
    # æ–°å¢: å°ç£è­‰åˆ¸äº¤æ˜“æ‰€)
    #("å°ç£è‚¡å¸‚ç„¦é»", "https://www.taifex.com.tw/cht/11/RSS2")
]

def fetch_cn_news():
    """å¾ä¸­å¤®ç¤¾åœ‹éš›ç²å–ä¸­æ–‡æ–°è"""
    name = "ä¸­å¤®ç¤¾åœ‹éš›"
    url = "https://feeds.feedburner.com/rsscna/intworld"
    html = ""
    try:
        r = requests.get(url, timeout=10)
        r.encoding = r.apparent_encoding
        root = ET.fromstring(r.text)
        items = root.findall(".//item")[:20]
        for item in items:
            title = item.find("title").text if item.find("title") is not None else "ç„¡æ¨™é¡Œ"
            link = item.find("link").text if item.find("link") is not None else "#"
            html += f'<li><a href="{link}" target="_blank">{title}</a> <small>({name})</small></li>\n'
    except Exception as e:
        html += f"<li>{name} è®€å–å¤±æ•—: {e}</li>\n"
    return html

# === æ”¿ç¶“æ‘˜è¦ ===
def fetch_geo():
    try:
        r = requests.get("https://www.reuters.com/world/", timeout=10)
        r.encoding = r.apparent_encoding
        soup_text = r.text
        links = re.findall(r'href="(/world/[^"]+)"', soup_text)[:8]
        geo_html = ""
        for link in links:
            url = "https://www.reuters.com" + link
            title = link.split("/")[-1].replace("-", " ").title()
            geo_html += f'<li><a href="{url}" target="_blank">{title}</a></li>\n'
        return geo_html
    except:
        return "<li>Reuters è®€å–å¤±æ•—</li>"

# === æ›´æ–°é¦–é  ===
def update_html():
    # now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
    # ğŸš¨ ä¿®æ­£æ™‚å€å•é¡Œï¼šä½¿ç”¨ pytz ç²å– Asia/Taipei (CST/GMT+8) æ™‚é–“
    taipei_tz = pytz.timezone('Asia/Taipei') 
    now_taipei = datetime.datetime.now(taipei_tz)
    
    # æ ¼å¼åŒ–æ™‚é–“æˆ³
    now_str = now_taipei.strftime("%Y-%m-%d %H:%M:%S (CST/GMT+8)")
    
    html_path = "index.html"
    with open(html_path, "r", encoding="utf-8") as f:
        html = f.read()

    # æ‰¾åˆ° <body> å¾Œç¬¬ä¸€å€‹ <h2>ğŸ“ˆ å…¨çƒè‚¡å¸‚æŒ‡æ•¸ çš„ä½ç½®
    body_start, sep, _ = html.partition("<h2>ğŸ“ˆ å…¨çƒè‚¡å¸‚æŒ‡æ•¸")
    head_part, sep_head, _ = body_start.partition("<body>")
    
    # ä¿ç•™ <head> å€å¡Šï¼Œåªå¾ <body> é–‹å§‹æ’å…¥æ–°è³‡æ–™
    html = head_part + sep_head  

    new_block = f"""
<h2>ğŸ“ˆ å…¨çƒè‚¡å¸‚æŒ‡æ•¸ï¼ˆæ›´æ–°æ™‚é–“ï¼š{now_str}ï¼‰</h2>
<ul>{fetch_markets()}</ul>

<h2>ğŸ“° åœ‹éš›é‡å¤§æ–°èï¼ˆè‹±æ–‡ï¼‰</h2>
<ul>{fetch_rss_news(RSS_LIST_EN)}</ul>

<h2>ğŸ“° åœ‹éš›é‡å¤§æ–°èï¼ˆä¸­æ–‡ï¼‰</h2>
<ul>{fetch_rss_news(RSS_LIST_CN)}</ul>

</body>
"""
    html += new_block

    # å¯«å› HTML
    with open(html_path, "w", encoding="utf-8") as f:
        f.write(html)

    #print("é¦–é æ›´æ–°å®Œæˆ âœ…")
    print(f"é¦–é æ›´æ–°å®Œæˆï¼Œæ™‚é–“ï¼š{now_str} âœ…")

if __name__ == "__main__":
    update_html()

